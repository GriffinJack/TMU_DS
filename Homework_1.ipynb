{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"hXVpl7jLbw_6"},"source":["### 1. Using Keras Library Implement an AutoEncoder for the MNIST dataset (15) (1D input)\n","AutoEncoders are one of the few unsupervised learning architectures of Deep Learning. (Authors: Dor Bank, Noam Koenigstein, Raja Giryes)\n","Reference: https://arxiv.org/pdf/2003.05991.pdf\n","\n","1. Build and train an autoencoder (10)\n","3. Do a write up on your understanding of how autoencoders work and some of its uses (5)\n","\n","## 2. Visualize the embeddings generated (5)\n","\n","Visualize the embeddings using T-SNE. \n","\n","TSNE is a really nice dimensionality reduction algorithm that is used for visualizgin high-dimensional dataset. Here are some links to read up on if you want to use TSNE\n","\n","1. https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding. \n","2. https://builtin.com/data-science/tsne-python\n","\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"F0wQx4QVq3JJ"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"CTJhPPIjq5p7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 1s 0us/step\n"]}],"source":["(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Y9d19hBMDyum"},"outputs":[],"source":["# flatten a 2D image into a 1D vector. \n","x_train = np.reshape(x_train, (-1, 784))\n","x_test = np.reshape(x_train, (-1, 784))"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"VaaEB2OpDQSM"},"outputs":[],"source":["x_train = x_train.astype('float32') / 255.\n","x_test = x_test.astype('float32') / 255."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":206,"status":"ok","timestamp":1674266564042,"user":{"displayName":"Kanchana Padmanabhan","userId":"16906781817953159303"},"user_tz":300},"id":"ekWK2G8kDUJ3","outputId":"21a4d5d2-b624-4806-ee90-fab553ff7341"},"outputs":[{"data":{"text/plain":["(60000, 784)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["x_train.shape"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"uQsKVMxNEF-a"},"outputs":[],"source":["encoding_dim = 32\n","\n","input_img = tf.keras.Input(shape=(784,))\n","\n","encoded = tf.keras.layers.Dense(encoding_dim, activation='relu')(input_img)\n","\n","decoded = tf.keras.layers.Dense(784, activation='sigmoid')(encoded)\n","\n","autoencoder = tf.keras.Model(input_img, decoded)\n","\n","encoder = tf.keras.Model(input_img, encoded)\n","\n","encoded_input = tf.keras.Input(shape=(encoding_dim,))\n","\n","decoder_layer = autoencoder.layers[-1]\n","\n","decoder = tf.keras.Model(encoded_input, decoder_layer(encoded_input))\n","\n","autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","235/235 [==============================] - 2s 6ms/step - loss: 0.2717 - val_loss: 0.1891\n","Epoch 2/50\n","235/235 [==============================] - 1s 5ms/step - loss: 0.1695 - val_loss: 0.1541\n","Epoch 3/50\n","235/235 [==============================] - 1s 6ms/step - loss: 0.1439 - val_loss: 0.1348\n","Epoch 4/50\n","235/235 [==============================] - 1s 5ms/step - loss: 0.1282 - val_loss: 0.1222\n","Epoch 5/50\n","235/235 [==============================] - 1s 5ms/step - loss: 0.1180 - val_loss: 0.1141\n","Epoch 6/50\n","235/235 [==============================] - 1s 5ms/step - loss: 0.1114 - val_loss: 0.1089\n","Epoch 7/50\n","235/235 [==============================] - 1s 5ms/step - loss: 0.1067 - val_loss: 0.1046\n","Epoch 8/50\n","235/235 [==============================] - 1s 6ms/step - loss: 0.1030 - val_loss: 0.1013\n","Epoch 9/50\n","235/235 [==============================] - 1s 6ms/step - loss: 0.1001 - val_loss: 0.0990\n","Epoch 10/50\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0980 - val_loss: 0.0971\n","Epoch 11/50\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0966 - val_loss: 0.0960\n","Epoch 12/50\n","235/235 [==============================] - 1s 6ms/step - loss: 0.0956 - val_loss: 0.0952\n","Epoch 13/50\n","235/235 [==============================] - 1s 6ms/step - loss: 0.0950 - val_loss: 0.0947\n","Epoch 14/50\n","235/235 [==============================] - 1s 6ms/step - loss: 0.0946 - val_loss: 0.0943\n","Epoch 15/50\n","235/235 [==============================] - 1s 6ms/step - loss: 0.0943 - val_loss: 0.0941\n","Epoch 16/50\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0941 - val_loss: 0.0938\n","Epoch 17/50\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0939 - val_loss: 0.0938\n","Epoch 18/50\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0937 - val_loss: 0.0936\n","Epoch 19/50\n","235/235 [==============================] - 1s 6ms/step - loss: 0.0936 - val_loss: 0.0934\n","Epoch 20/50\n","235/235 [==============================] - 1s 6ms/step - loss: 0.0935 - val_loss: 0.0934\n","Epoch 21/50\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0934 - val_loss: 0.0933\n","Epoch 22/50\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0933 - val_loss: 0.0932\n","Epoch 23/50\n","235/235 [==============================] - 1s 6ms/step - loss: 0.0933 - val_loss: 0.0932\n","Epoch 24/50\n","235/235 [==============================] - 1s 6ms/step - loss: 0.0932 - val_loss: 0.0931\n","Epoch 25/50\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0931 - val_loss: 0.0931\n","Epoch 26/50\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0931 - val_loss: 0.0930\n","Epoch 27/50\n","235/235 [==============================] - 1s 6ms/step - loss: 0.0930 - val_loss: 0.0929\n","Epoch 28/50\n","235/235 [==============================] - 1s 6ms/step - loss: 0.0930 - val_loss: 0.0929\n","Epoch 29/50\n","235/235 [==============================] - 1s 6ms/step - loss: 0.0930 - val_loss: 0.0928\n","Epoch 30/50\n","235/235 [==============================] - 1s 6ms/step - loss: 0.0929 - val_loss: 0.0929\n","Epoch 31/50\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0929 - val_loss: 0.0928\n","Epoch 32/50\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0929 - val_loss: 0.0928\n","Epoch 33/50\n","235/235 [==============================] - 1s 6ms/step - loss: 0.0929 - val_loss: 0.0927\n","Epoch 34/50\n","235/235 [==============================] - 1s 6ms/step - loss: 0.0928 - val_loss: 0.0928\n","Epoch 35/50\n","235/235 [==============================] - 1s 6ms/step - loss: 0.0928 - val_loss: 0.0927\n","Epoch 36/50\n","235/235 [==============================] - 1s 6ms/step - loss: 0.0928 - val_loss: 0.0927\n","Epoch 37/50\n","235/235 [==============================] - 1s 6ms/step - loss: 0.0928 - val_loss: 0.0927\n","Epoch 38/50\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0928 - val_loss: 0.0927\n","Epoch 39/50\n","235/235 [==============================] - 1s 6ms/step - loss: 0.0927 - val_loss: 0.0926\n","Epoch 40/50\n","235/235 [==============================] - 1s 6ms/step - loss: 0.0927 - val_loss: 0.0927\n","Epoch 41/50\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0927 - val_loss: 0.0927\n","Epoch 42/50\n","235/235 [==============================] - 1s 6ms/step - loss: 0.0927 - val_loss: 0.0927\n","Epoch 43/50\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0927 - val_loss: 0.0926\n","Epoch 44/50\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0927 - val_loss: 0.0926\n","Epoch 45/50\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0927 - val_loss: 0.0925\n","Epoch 46/50\n","235/235 [==============================] - 1s 6ms/step - loss: 0.0926 - val_loss: 0.0926\n","Epoch 47/50\n","235/235 [==============================] - 1s 6ms/step - loss: 0.0926 - val_loss: 0.0926\n","Epoch 48/50\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0926 - val_loss: 0.0925\n","Epoch 49/50\n","235/235 [==============================] - 1s 5ms/step - loss: 0.0926 - val_loss: 0.0925\n","Epoch 50/50\n","235/235 [==============================] - 1s 6ms/step - loss: 0.0926 - val_loss: 0.0925\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x26c9a7b6350>"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["autoencoder.fit(x_train, x_train,epochs=50,batch_size=256,shuffle=True, validation_data=(x_test,x_test))\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPcMHfpuAS69GKq0swkGOlt","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"e9f5ae0b844ea69b95fb7f4223e0d68f8c35cee7b332b74b146d8b3492cc9b7c"}}},"nbformat":4,"nbformat_minor":0}
